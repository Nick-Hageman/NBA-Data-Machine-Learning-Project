{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-Analysis Data Considerations: Yes there were missing values, to account for them I either replaced those spots with data that would attempt to keep it consistent like for example for the weight and height I just used the mean of each respective column. For other values like assists and rebounds, missing values meant nothing was recorded so I inserted 0's in those positions. And for any strings I also tried to replace them with numerical values to try to reflect patterns in relation with how many points they'd score. I also got rid of any rows that contained NaN values in the end for safe measures.\n",
    "I tried to include only the features that had a linear relationship with the amount of points each player scored.\n",
    "Features are discussed in depth below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Project 1, Nick Hageman and Nathan Schaefer\n",
    "import csv\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import (datasets, neighbors,\n",
    "                     naive_bayes,\n",
    "                     model_selection as skms,\n",
    "                     linear_model, dummy,\n",
    "                     metrics,\n",
    "                     pipeline,\n",
    "                     preprocessing as skpre)\n",
    "\n",
    "#import ipywidgets as widgets\n",
    "#from ipywidgets import interact\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below cell are the chosen features for the model. I tried to choose only the features that would be good in differentiating players in relation to how many points they'd score to improve it's predictions. Some of these columns had missing values so I will talk about how I dealt with those in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Choosing features\n",
    "features = [\n",
    "    \"HEIGHT\",\n",
    "    \"WEIGHT\",\n",
    "    \"SEASON_EXP\",\n",
    "    \"AST\",\n",
    "    \"REB\",\n",
    "    \"PIE\",\n",
    "    \"DLEAGUE_FLAG\",\n",
    "    \"ALL_STAR_APPEARANCES\",\n",
    "    \"DRAFT_ROUND\",\n",
    "    \"POSITION\",\n",
    "    \"PTS\"\n",
    "]\n",
    "\n",
    "features2 = [\n",
    "    \"HEIGHT\",\n",
    "    \"WEIGHT\",\n",
    "    \"SEASON_EXP\",\n",
    "    \"AST\",\n",
    "    \"REB\",\n",
    "    \"PIE\",\n",
    "    \"ALL_STAR_APPEARANCES\",\n",
    "    \"DRAFT_ROUND\",\n",
    "    'POSITION',\n",
    "    \"DLEAGUE_FLAG\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the assits, rebounds, player impact estimate, and all star appearances, I assumed that if there were missing values that they just didn't have any of those contributions and didn't want to replace them with a mean of the other values. So what I ended up doing is replacing them with 0's because I didn't want to throw off the model. This however was not the case for height and weight because the players missing these values couldn't possibly have a height/weight of 0 so I just put the sum of the respective columns to try to keep the data consistent. For the draft round feature, there were some values that were strings \"Undrafted\" which I replaced with 4 because I wanted to associate them with players chosen in the late rounds because they weren't drafted at all. I used a similar strategy with the position to try to reflect which positions would be scoring the most points and assigning them to the highest values. Lastly, I changed the DLEAGUE_FLAG values to 1's and 0's so it could be interpreted rather than getting errors for being a string. For safe measure I removed all rows that contained NaN values to ensure there were no errors. I also had to convert the numerical values to float16 types which I don't fully understand why but fixed the errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nickh\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:6392: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return self._update_inplace(result)\n",
      "C:\\Users\\nickh\\AppData\\Local\\Temp/ipykernel_18060/2029923554.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_train_drop[\"DRAFT_ROUND\"] = data_train_drop[\"DRAFT_ROUND\"].replace(\"Undrafted\", 4).replace(\"None\", 4).astype(float)\n",
      "C:\\Users\\nickh\\AppData\\Local\\Temp/ipykernel_18060/2029923554.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_train_drop[\"POSITION\"] = data_train_drop[\"POSITION\"].replace(\"Center\", 2).replace(\"Forward\", 8).replace(\"Guard\", 3).replace(\"Center-Forward\", 7).replace(\"Guard-Forward\", 6).replace(\"Forward-Center\", 5).replace(\"Forward-Guard\", 4).astype(float)\n",
      "C:\\Users\\nickh\\AppData\\Local\\Temp/ipykernel_18060/2029923554.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_train_drop[\"DLEAGUE_FLAG\"] = data_train_drop[\"DLEAGUE_FLAG\"].apply(conversion)\n",
      "C:\\Users\\nickh\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_train_df = pd.read_csv(\"train.csv\") \n",
    "\n",
    "data_train_drop = data_train_df[features]\n",
    "# Modifying any rows with missing/string values\n",
    "data_train_drop[\"AST\"].fillna(0, inplace = True)\n",
    "data_train_drop[\"REB\"].fillna(0, inplace = True)\n",
    "data_train_drop[\"PIE\"].fillna(0, inplace = True)\n",
    "data_train_drop[\"ALL_STAR_APPEARANCES\"].fillna(0, inplace = True)\n",
    "data_train_drop[\"HEIGHT\"].fillna(data_train_drop[\"HEIGHT\"].mean(), inplace = True)\n",
    "data_train_drop[\"WEIGHT\"].fillna(data_train_drop[\"WEIGHT\"].mean(), inplace = True)\n",
    "data_train_drop[\"DRAFT_ROUND\"] = data_train_drop[\"DRAFT_ROUND\"].replace(\"Undrafted\", 4).replace(\"None\", 4).astype(float)\n",
    "data_train_drop[\"POSITION\"] = data_train_drop[\"POSITION\"].replace(\"Center\", 2).replace(\"Forward\", 8).replace(\"Guard\", 3).replace(\"Center-Forward\", 7).replace(\"Guard-Forward\", 6).replace(\"Forward-Center\", 5).replace(\"Forward-Guard\", 4).astype(float)\n",
    "data_train_drop[\"POSITION\"].fillna(0, inplace = True)\n",
    "\n",
    "#Converts Y/N strings to 1's and 0's\n",
    "def conversion(x):\n",
    "    if x == \"Y\":\n",
    "        return(1)\n",
    "    elif x == \"N\":\n",
    "        return(0)\n",
    "data_train_drop[\"DLEAGUE_FLAG\"] = data_train_drop[\"DLEAGUE_FLAG\"].apply(conversion)\n",
    "\n",
    "#Remove all rows with NaN values\n",
    "data_train_drop.dropna(inplace=True)\n",
    "data_train_df = data_train_drop.copy()\n",
    "\n",
    "#converts to float16 types\n",
    "for feature in features:\n",
    "    if feature != 'PTS':\n",
    "        data_train_df[feature] = data_train_df[feature].convert_dtypes(np.float16)\n",
    "        data_train_df[feature] = data_train_df[feature].convert_dtypes(np.float16)\n",
    "\n",
    "data_train_ft = pd.DataFrame(data_train_df[features2])\n",
    "data_train_tgt = data_train_df[\"PTS\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I did a training/test split to get different data to 1) find the best model and 2) use the other set to fit the model. I tried to test linear regression and several different models of KNN with various values of k by utilizing Cross Validation. The model with the lowest RMSE would be chosen as the best model and would be used to fit the data, Linear regression came on top every time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 2.70\n",
      "1-NN: 3.77\n",
      "3-NN: 3.15\n",
      "5-NN: 3.09\n",
      "7-NN: 3.15\n",
      "9-NN: 3.18\n",
      "11-NN: 3.21\n",
      "13-NN: 3.25\n",
      "15-NN: 3.26\n",
      "\n",
      "Best model: lr; RMSE: 2.70\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#----------------------------------\n",
    "# Split into training/testing data \n",
    "#----------------------------------\n",
    "(data_train_plus_validation_ftrs, data_test_ftrs,\n",
    " data_train_plus_validation_tgt, data_test_tgt) = skms.train_test_split(data_train_ft,\n",
    "                                                                      data_train_tgt,\n",
    "                                                                      test_size=.30,\n",
    "                                                                      random_state = 39)\n",
    "\n",
    "# define dictionary of models to try\n",
    "models_to_try = {'lr': linear_model.LinearRegression()}\n",
    "# add k-NN models with various values of k to models_to_try\n",
    "for k in range(1,16,2):\n",
    "    models_to_try[f'{k}-NN'] = neighbors.KNeighborsRegressor(n_neighbors=k)\n",
    "\n",
    "# compute rmse for each model using k-fold cross-validation\n",
    "model_rmse = {}\n",
    "for model_name in models_to_try:\n",
    "    scores = skms.cross_val_score(models_to_try[model_name],\n",
    "                                  data_train_plus_validation_ftrs,\n",
    "                                  data_train_plus_validation_tgt,\n",
    "                                  cv=5,\n",
    "                                  scoring='neg_mean_squared_error')\n",
    "    # convert score to rmse\n",
    "    mean_rmse = np.sqrt(-scores.mean())\n",
    "    print(f'{model_name}: {mean_rmse:.2f}')\n",
    "    model_rmse[model_name] = mean_rmse\n",
    "\n",
    "# get model with lowest error\n",
    "best_model_name = min(model_rmse,key=model_rmse.get)\n",
    "print(f'\\nBest model: {best_model_name}; RMSE: {model_rmse[best_model_name]:.2f}')\n",
    "best_model = models_to_try[best_model_name]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I just modified the test data to be able to make predictions with my model just like how I modified the features earlier. I then fit the data on the model, made my predictions, and recorded them on a csv file to submit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nickh\\AppData\\Local\\Temp/ipykernel_18060/987385040.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  submission_ftrs[\"DLEAGUE_FLAG\"] = submission_ftrs[\"DLEAGUE_FLAG\"].apply(conversion)\n",
      "C:\\Users\\nickh\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:6392: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return self._update_inplace(result)\n",
      "C:\\Users\\nickh\\AppData\\Local\\Temp/ipykernel_18060/987385040.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  submission_ftrs[\"DRAFT_ROUND\"] = submission_ftrs[\"DRAFT_ROUND\"].replace(\"Undrafted\", 4).replace(\"None\", 4).astype(float)\n",
      "C:\\Users\\nickh\\AppData\\Local\\Temp/ipykernel_18060/987385040.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  submission_ftrs[\"POSITION\"] = submission_ftrs[\"POSITION\"].replace(\"Center\", 2).replace(\"Forward\", 8).replace(\"Guard\", 3).replace(\"Center-Forward\", 7).replace(\"Guard-Forward\", 6).replace(\"Forward-Center\", 5).replace(\"Forward-Guard\", 4).astype(float)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# This is just using the test.csv to setup a dataframe of the correct size\n",
    "# and indicies (the \"id\" field).\n",
    "make_submission_df = pd.read_csv(\"test.csv\")\n",
    "submission_ftrs = make_submission_df[features2]\n",
    "\n",
    "#Modify testing data\n",
    "submission_ftrs[\"DLEAGUE_FLAG\"] = submission_ftrs[\"DLEAGUE_FLAG\"].apply(conversion)\n",
    "submission_ftrs[\"AST\"].fillna(0, inplace = True)\n",
    "submission_ftrs[\"REB\"].fillna(0, inplace = True)\n",
    "submission_ftrs[\"PIE\"].fillna(0, inplace = True)\n",
    "submission_ftrs[\"ALL_STAR_APPEARANCES\"].fillna(0, inplace = True)\n",
    "submission_ftrs[\"HEIGHT\"].fillna(submission_ftrs[\"HEIGHT\"].mean(), inplace = True)\n",
    "submission_ftrs[\"WEIGHT\"].fillna(submission_ftrs[\"WEIGHT\"].mean(), inplace = True)\n",
    "submission_ftrs[\"DRAFT_ROUND\"] = submission_ftrs[\"DRAFT_ROUND\"].replace(\"Undrafted\", 4).replace(\"None\", 4).astype(float)\n",
    "submission_ftrs[\"POSITION\"] = submission_ftrs[\"POSITION\"].replace(\"Center\", 2).replace(\"Forward\", 8).replace(\"Guard\", 3).replace(\"Center-Forward\", 7).replace(\"Guard-Forward\", 6).replace(\"Forward-Center\", 5).replace(\"Forward-Guard\", 4).astype(float)\n",
    "submission_ftrs[\"POSITION\"].fillna(0, inplace = True)\n",
    "\n",
    "# drop all columns except 'id'\n",
    "make_submission_df = make_submission_df[['id']]\n",
    "# make sure the column of ID's that we just read in is the index column\n",
    "make_submission_df = make_submission_df.set_index('id')\n",
    "\n",
    "#predictions = np.random.rand(1350)*5\n",
    "fit = best_model.fit(data_test_ftrs, data_test_tgt)\n",
    "predictions = best_model.predict(submission_ftrs)\n",
    "\n",
    "# Here, you add your predictions to the dataframe\n",
    "make_submission_df['PTS'] = predictions\n",
    "\n",
    "# Either one of these will work\n",
    "# The first one will round all floating point numbers to 2 decimals\n",
    "# Makes it easier to look at.\n",
    "make_submission_df.to_csv('submission.csv',sep=',', float_format='%.2f')\n",
    "#make_submission_df.to_csv('submission.csv',sep=',')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c8610bb4a80ac6b87b3433d5c4f8bc5eaf2129f71828e941c66594fe0173a8dd"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
